## Generate training and/or validation datasets.
Please follow the instructions at https://doi.org/10.7924/r48g8tf24 to download and place the relevant datasets in their respective locations to run the example training / data generation scripts.

Dataset generation configurations can be modified by changing the relevant values in `config.py`. Data collection is conducted in `n_batches` batches, with each batch consisting of `batch_size * axons_per_minibatch` axon simulations.

|Variable|Description|
|---|---|
|`filename`|Name of dataset file. If `None`, will generate a name that incorporates information about distribution of fiber diameters, pulse widths, and amplitudes.|
|`n_batches`|Batches of data collection. **Default: 64**.|
|`batch_size`|Size of data collection batch (# minibatches) **Default: 32**.|
|`axons_per_minibatch`|# axons per minibatch of data collection. **Default: 32**.|
|`tstop`|Simulation length [ms]. **Default: 5.0**.|
|`n_node_record`|# Nodes of Ranvier from which to record. **Default: 53**.|
|`n_contacts`|Number of contacts in stimulating electrode used to generate data. **Default: 6**.|
|`round`|Round of data generation. You may wish to generate multiple datasets using the same distribution. Convenient way to avoid filename collisions (just increment `round`). **Default: 0**.|
|`diameter`|Diameter to simulate if only generating data for one axon diameter. **Default: 5.7 $\mu m$**.|
|`use_dr`|Whether to simulate a range of axon diameters. **Default: True**.|
|`min_diam`|Lower bound of axon diameter range. **Default: 5.7 $\mu m$**.|
|`max_diam`|Upper bound of axon diameter range. **Default: 14.0 $\mu m$**.|
|`max_amp`| Current amplitudes of monophasic rectangular pulses delivered from each contact will be randomly sampled `~U[-max_amp, max_amp)`. **Default: 0.2 mA**.|
|`max_pw`| Pulse widths of monophasic rectangular pulses delivered from each contact will be randomly sampled `~U[0, max_pw)`. **Default: 2.0 ms**.|
|`max_delay`| Delays of monophasic rectangular pulses delivered from each contact will be randomly sampled `~U[0, max_delay)`. **Default: 2.0 ms**.|
|`record_e`| Whether to record extracellular potentials. **Default: True**.|
|`record_v`| Whether to record membrane potential. **Default: True**.||

Once you've set variables as you wish in `config.py`, you can initiate dataset generation:

```bash
(base) foo@bar : ~ $ cd /path/to/cloned/repository/data
(base) foo@bar : /path/to/cloned/repository/data $ conda activate axonml
(axonml) foo@bar : /path/to/cloned/repository/data $ python generate_data.py
```

Config parameters can be also be set using command line arguments. For example, to run 128 batches (instead of default 64) with delays from 0 to 1 ms (instead of 2 ms):

```bash
(axonml) foo@bar : ./data $ python generate_data.py --n_batches 128 --max_delay 2
```

Command line arguments take precedence over values set in `config.py`.

> [!IMPORTANT]
> Generating large datasets will take a **very** long on a single CPU core. We have included an example bash script (`dgen.sh`) illustrating how to distribute this operation across several cores on an MPI-enabled cluster using `SLURM` (the only change is executing `mpirun -n $N_CORES python generate_data.py` instead of just `python generate_data.py`). Note that depending on your MPI installation, you may need to use `mpiexec` instead of `mpirun`.

> [!IMPORTANT]
> To generate data in parallel, you **must** have `h5py` built against parallel HDF5. See [here](https://docs.h5py.org/en/latest/mpi.html) and [here](https://accserv.lepp.cornell.edu/svn/packages/hdf5/release_docs/INSTALL_parallel) for instructions.

## Consolidate generated data.

After the dataset generation algorithm has run, the data must be consolidated into a format that can be consumed by the training algorithm. Use `consolidate_data.py` to do this:

```bash
(base) foo@bar : ~ $ cd ./data
(base) foo@bar : ./data $ conda activate axonml
(axonml) foo@bar : ./data $ python consolidate_data.py -f filename -t consolidated_data_filename
```
Where `filename` is the name of the file generated by `generate_data.py`.
This will generate a dataset file `consolidated_data_filename` which can be used for training / validation (set path in `config.py`).